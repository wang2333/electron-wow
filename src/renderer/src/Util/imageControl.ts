import { Mat, Point, Scalar } from '@techstark/opencv-js'

const Jimp = window.Jimp
const cv = window.cv
const Tesseract = window.tesseract

// å®šä¹‰ç‰¹å¾æˆªå›¾çš„å¤§å°
const CROP_SIZE = 30
/** é›·è¾¾åˆ°æŒ‡é’ˆxé—´è· */
export const leidaPaddingX = 70
/** é›·è¾¾åˆ°æŒ‡é’ˆyé—´è· */
export const leidaPaddingY = 65
/** é›·è¾¾æŒ‡é’ˆxåæ ‡ */
export const leidaPointerX = 1168
/** é›·è¾¾æŒ‡é’ˆyåæ ‡ */
export const leidaPointerY = 130
/** é›·è¾¾æŒ‡é’ˆå®½åº¦ */
export const leidaPointerWidth = 18
/** é›·è¾¾æŒ‡é’ˆé«˜åº¦ */
export const leidaPointerHeight = 18

/** base64å›¾ç‰‡ç”ŸæˆimgèŠ‚ç‚¹ */
export const base64ToImage = async (base64: string): Promise<HTMLImageElement> => {
  return new Promise((resolve, reject) => {
    const img = new Image()
    img.src = base64
    img.onload = () => resolve(img)
    img.onerror = (err) => reject(err)
  })
}

/** åŠ è½½Base64å›¾åƒå¹¶è½¬æ¢ä¸ºOpenCVçŸ©é˜µ */
export const base64ToMat = async (base64: string) => {
  const imageElement = await base64ToImage(base64)
  return cv.imread(imageElement)
}

/** æ ¹æ®canvasè·å–base64å›¾ç‰‡ */
export const matToBase64 = (mat: Mat) => {
  const canvas = document.createElement('canvas')
  cv.imshow(canvas, mat)
  return canvas.toDataURL('image/png')
}

/** æ ¹æ®å›¾ç‰‡è·¯å¾„è½¬æ¢ä¸ºbase64å›¾ç‰‡ */
export const imageToBase64 = async (path: string) => {
  const image = await Jimp.read(path)
  const base64 = await image.getBase64Async(Jimp.MIME_PNG)
  return base64
}

/** è¯»å–å›¾åƒå¹¶è½¬æ¢ä¸ºOpenCVçŸ©é˜µ */
export const imageToMat = async (path: string) => {
  const base64 = await imageToBase64(path)
  const imageElement = await base64ToImage(base64)
  return cv.imread(imageElement)
}

/** OpenCVçŸ©é˜µæ¸²æŸ“åˆ°æŒ‡å®šcanvas */
export const matToCanvas = (mat: Mat, canvas: string) => {
  cv.imshow(canvas, mat)
}

/** è®¡ç®—çŸ©é˜µåŒ¹é…ç‚¹çš„ä¸­å¿ƒç‚¹ */
export const calculateCenter = (point: Point, mat: Mat) => {
  return new cv.Point(point.x + mat.cols / 2, point.y + mat.rows / 2)
}

/** è®¡ç®—ä¸¤ä¸ªç‚¹ä¹‹é—´çš„è·ç¦» */
export const calculateDistance = (point1: Point, point2: Point): number => {
  return Math.sqrt(Math.pow(point2.x - point1.x, 2) + Math.pow(point2.y - point1.y, 2))
}

/** è®¡ç®—ä¸¤ä¸ªç‚¹ä¹‹é—´çš„è§’åº¦ï¼Œä»¥æ­£åŒ—æ–¹å‘ä¸º0åº¦ */
export const calculateAngle = (current: Point, target: Point): number => {
  let angle = 0
  // ç›®æ ‡ç‚¹åœ¨å·¦ä¸Š
  if (current.x > target.x && current.y > target.y) {
    angle = Math.atan2(current.x - target.x, current.y - target.y) * (180 / Math.PI)
  }
  // ç›®æ ‡ç‚¹åœ¨å³ä¸Š
  if (current.x < target.x && current.y > target.y) {
    angle = -1 * (Math.atan2(target.x - current.x, current.y - target.y) * (180 / Math.PI))
  }
  // ç›®æ ‡ç‚¹åœ¨å·¦ä¸‹
  if (current.x > target.x && current.y < target.y) {
    angle = 180 - Math.atan2(current.x - target.x, target.y - current.y) * (180 / Math.PI)
  }
  // ç›®æ ‡ç‚¹åœ¨å³ä¸‹
  if (current.x < target.x && current.y < target.y) {
    angle = -1 * (180 - Math.atan2(target.x - current.x, target.y - current.y) * (180 / Math.PI))
  }

  return angle
}

/** ç»˜åˆ¶çŸ©å½¢æ¡† */
export const drawRectangle = (paneMat: Mat, topLeft: Point, mat: Mat, color: Scalar): void => {
  const bottomRight = new cv.Point(topLeft.x + mat.cols, topLeft.y + mat.rows)
  cv.rectangle(paneMat, topLeft, bottomRight, color, 2, cv.LINE_8, 0)
}

/** ç»˜åˆ¶è¿çº¿ */
export const drawLine = (paneMat: Mat, point1: Point, point2: Point, color: Scalar): void => {
  cv.line(paneMat, point1, point2, color, 2, cv.LINE_8, 0)
}

// ç¡®ä¿è£å‰ªä¸è¶…å‡ºè¾¹ç•Œ
export const safeCrop = (
  src: Mat,
  centerX: number,
  centerY: number,
  width: number,
  height: number
) => {
  const x = centerX - Math.floor(width / 2)
  const y = centerY - Math.floor(height / 2)
  const rect = new cv.Rect(x, y, width, height)
  return src.roi(rect)
}

/** ä¿å­˜å›¾ç‰‡ */
export const imageDataToBase64 = async (
  imageData: { width: number; height: number; data: Buffer },
  path?: string
) => {
  const buffer = Buffer.from(imageData.data)
  // å¤„ç†å¹¶ä¿å­˜å›¾åƒ
  const jimpImage = new Jimp({
    data: buffer,
    width: imageData.width,
    height: imageData.height
  })
  if (path) {
    await jimpImage.writeAsync(path)
  }
  const base64 = await jimpImage.getBase64Async(Jimp.MIME_PNG)
  return base64
}

/** è·å–å›¾åƒä½ç½®å¹¶ç»˜åˆ¶åŒ¹é…ç»“æœ */
export const getImagePosition = async (
  targetBase64: string,
  target: { leftImg: string; rightImg: string; topImg: string; bottomImg: string },
  current: { leftImg: string; rightImg: string; topImg: string; bottomImg: string }
) => {
  // è¯»å–å¤§å›¾å¹¶è½¬æ¢ä¸ºOpenCVçŸ©é˜µ
  const mat = await base64ToMat(targetBase64)

  // è½¬ä¸ºç°åº¦å›¾åƒ
  // cv.cvtColor(mat, mat, cv.COLOR_RGBA2GRAY)

  // åˆå§‹åŒ–æœ€ä½³åŒ¹é…ç»“æœ
  let bestMatch: any = null

  const directions = [
    'leftImg',
    'rightImg',
    'topImg',
    'bottomImg'
    // 'leftTopImg'
    // 'leftBottomImg',
    // 'rightTopImg',
    // 'rightBottomImg'
  ]

  // éå†æ¯ä¸ªæ–¹å‘è¿›è¡ŒåŒ¹é…
  for (const direction of directions) {
    const matchResult = await matchAndDraw(mat, current[direction], target[direction])

    // å¦‚æœå½“å‰çš„ bestMatch è¿˜æ²¡æœ‰åˆå§‹åŒ–ï¼Œåˆ™åˆå§‹åŒ–å®ƒ
    if (!bestMatch) {
      bestMatch = matchResult
    }

    // æ£€æŸ¥æ˜¯å¦å­˜åœ¨ç›¸åŒçš„ distance å’Œ angle
    if (
      bestMatch &&
      matchResult.score > 0.9 &&
      matchResult.distance === bestMatch.distance &&
      matchResult.angle === bestMatch.angle
    ) {
      // å¦‚æœæ‰¾åˆ°ç›¸åŒçš„ distance å’Œ angleï¼Œè¿”å›è¿™æ¡æ•°æ®
      bestMatch = matchResult
    }
  }

  cv.imshow('canvasOutput2', mat)
  // é‡Šæ”¾å¤§å›¾çŸ©é˜µçš„å†…å­˜
  mat.delete()

  // è¿”å›æœ€ä½³åŒ¹é…çš„è·ç¦»å’Œè§’åº¦
  return {
    distance: +bestMatch.distance,
    angle: +bestMatch.angle,
    score: bestMatch.score === 1 ? 0 : bestMatch.score
  }
}

/** è¿›è¡Œæ¨¡æ¿åŒ¹é…å¹¶ç»˜åˆ¶åŒ¹é…æ¡†å’Œè¿çº¿ */
const matchAndDraw = async (paneMat: Mat, currentImg: string, targetImg: string) => {
  const [curentMat, targetMat] = await Promise.all([
    base64ToMat(currentImg),
    base64ToMat(targetImg)
  ])

  // è½¬ä¸ºç°åº¦å›¾åƒ
  // cv.cvtColor(curentMat, curentMat, cv.COLOR_RGBA2GRAY)
  // cv.cvtColor(targetMat, targetMat, cv.COLOR_RGBA2GRAY)

  // å¯¹å›¾åƒè¿›è¡ŒäºŒå€¼åŒ–å¤„ç†
  // cv.threshold(curentMat, curentMat, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)
  // cv.threshold(targetMat, targetMat, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)

  // è¿›è¡Œæ¨¡æ¿åŒ¹é…
  const resultCurrent = new cv.Mat()
  const resultTarget = new cv.Mat()
  const mask = new cv.Mat()

  cv.matchTemplate(paneMat, curentMat, resultCurrent, cv.TM_CCOEFF_NORMED, mask)
  cv.matchTemplate(paneMat, targetMat, resultTarget, cv.TM_CCOEFF_NORMED, mask)

  const maxPointCurrent = cv.minMaxLoc(resultCurrent, mask).maxLoc
  const maxPointTarget = cv.minMaxLoc(resultTarget, mask).maxLoc

  // è®¡ç®—åŒ¹é…ä¸­å¿ƒç‚¹
  const centerCurrent = calculateCenter(maxPointCurrent, curentMat)
  const centerTarget = calculateCenter(maxPointTarget, targetMat)

  // è®¡ç®—è·ç¦»å’Œè§’åº¦
  const distance = calculateDistance(centerCurrent, centerTarget)
  const angle = calculateAngle(centerCurrent, centerTarget)

  // è·å–åŒ¹é…åº¦ï¼ˆåˆ†æ•°ï¼‰
  const score = cv.minMaxLoc(resultTarget, mask).maxVal

  // ç»˜åˆ¶åŒ¹é…æ¡†å’Œè¿çº¿
  drawRectangle(paneMat, maxPointCurrent, curentMat, new cv.Scalar(255, 0, 0, 255)) // çº¢è‰²æ¡†è¡¨ç¤º current
  drawRectangle(paneMat, maxPointTarget, targetMat, new cv.Scalar(0, 255, 0, 255)) // ç»¿è‰²æ¡†è¡¨ç¤º target
  drawLine(paneMat, centerCurrent, centerTarget, new cv.Scalar(0, 0, 255, 255)) // è“è‰²çº¿

  // é‡Šæ”¾å†…å­˜
  curentMat.delete()
  targetMat.delete()
  resultCurrent.delete()
  resultTarget.delete()
  mask.delete()

  return { distance: +distance, angle: +angle, score: +score === 1 ? 0 : +score }
}

/** è·å–å›¾ç‰‡çš„4ä¸ªç‰¹å¾å°å›¾ */
export const getImageFourFeature = async (base64: string) => {
  const src = await base64ToMat(base64)

  // Calculate the center point
  const centerX = Math.floor(src.cols / 2)
  const centerY = Math.floor(src.rows / 2)

  const centerImg = safeCrop(src, centerX, centerY, leidaPointerWidth, leidaPointerHeight)
  const leftImg = safeCrop(src, centerX - CROP_SIZE, centerY, CROP_SIZE, CROP_SIZE)
  const rightImg = safeCrop(src, centerX + CROP_SIZE, centerY, CROP_SIZE, CROP_SIZE)
  const topImg = safeCrop(src, centerX, centerY - CROP_SIZE, CROP_SIZE, CROP_SIZE)
  const bottomImg = safeCrop(src, centerX, centerY + CROP_SIZE, CROP_SIZE, CROP_SIZE)

  const obj = {
    centerImg: matToBase64(centerImg),
    leftImg: matToBase64(leftImg),
    rightImg: matToBase64(rightImg),
    topImg: matToBase64(topImg),
    bottomImg: matToBase64(bottomImg)
  }

  // Clean up
  src.delete()
  centerImg.delete()
  leftImg.delete()
  rightImg.delete()
  topImg.delete()
  bottomImg.delete()

  return obj
}

/** æ—‹è½¬æ‰¾å›¾ */
export const processImages = async (queryImg: string, templateImg: string) => {
  // 1. åŠ è½½æ¨¡æ¿å’Œç›®æ ‡å›¾åƒ
  const [src, template] = await Promise.all([base64ToMat(queryImg), base64ToMat(templateImg)])

  // è½¬ä¸ºç°åº¦å›¾åƒ
  cv.cvtColor(src, src, cv.COLOR_RGBA2GRAY)
  cv.cvtColor(template, template, cv.COLOR_RGBA2GRAY)

  // å¯¹å›¾åƒè¿›è¡ŒäºŒå€¼åŒ–å¤„ç†
  cv.threshold(src, src, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)
  cv.threshold(template, template, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)

  let bestMatchVal = -1
  let bestAngle = 0
  let bestLocation = { x: 0, y: 0 }

  // 2. ä¾æ¬¡æ—‹è½¬æ¨¡æ¿å›¾åƒ
  for (let angle = 0; angle < 360; angle += 2) {
    // ä»¥2åº¦ä¸ºæ­¥é•¿
    // è®¡ç®—æ—‹è½¬çŸ©é˜µ
    const center = new cv.Point(template.cols / 2, template.rows / 2)
    const rotMat = cv.getRotationMatrix2D(center, angle, 1.0)

    // æ—‹è½¬å›¾åƒ
    const rotatedTemplate = new cv.Mat()
    const dsize = new cv.Size(template.cols, template.rows)
    cv.warpAffine(
      template,
      rotatedTemplate,
      rotMat,
      dsize,
      cv.INTER_LINEAR,
      cv.BORDER_CONSTANT,
      new cv.Scalar()
    )

    // 3. æ‰§è¡Œæ¨¡æ¿åŒ¹é…
    const result = new cv.Mat()
    const mask = new cv.Mat()
    cv.matchTemplate(src, rotatedTemplate, result, cv.TM_CCOEFF_NORMED, mask)

    // TM_SQDIFF 126
    // TM_SQDIFF_NORMED 136
    // 4. æ‰¾åˆ°æœ€ä½³åŒ¹é…
    const minMax = cv.minMaxLoc(result, mask)
    const maxVal = minMax.maxVal
    const maxLoc = minMax.maxLoc

    // console.log('ğŸ‘» ~ maxVal:', angle, maxVal.toFixed(4))
    // cv.imshow('canvasOutput', src)
    // cv.imshow('canvasOutput2', rotatedTemplate)

    if (maxVal > bestMatchVal) {
      bestMatchVal = maxVal
      bestAngle = angle
      bestLocation = maxLoc
    }

    // æ¸…ç†å†…å­˜
    rotatedTemplate.delete()
    result.delete()
    mask.delete()
  }

  // æ¸…ç†å†…å­˜
  src.delete()
  template.delete()

  return {
    angle: bestAngle,
    bestLocation,
    bestMatchVal
  }
}

export const detectMovement = async (currentImg: string, targetImg: string) => {
  const [curentMat, targetMat] = await Promise.all([
    base64ToMat(currentImg),
    base64ToMat(targetImg)
  ])

  // Convert to grayscale
  const grayCurrent = new cv.Mat()
  const grayPrevious = new cv.Mat()
  cv.cvtColor(curentMat, grayCurrent, cv.COLOR_BGR2GRAY)
  cv.cvtColor(targetMat, grayPrevious, cv.COLOR_BGR2GRAY)

  // Create ORB object
  const orb = new cv.ORB(5000, 1.2, 8, 15)

  // Detect ORB keypoints and descriptors
  const keypoints1 = new cv.KeyPointVector()
  const keypoints2 = new cv.KeyPointVector()
  const descriptors1 = new cv.Mat()
  const descriptors2 = new cv.Mat()
  orb.detectAndCompute(grayPrevious, new cv.Mat(), keypoints1, descriptors1)
  orb.detectAndCompute(grayCurrent, new cv.Mat(), keypoints2, descriptors2)

  // Check if descriptors are empty
  if (descriptors1.rows === 0 || descriptors2.rows === 0) {
    return { distance: 0, angle: 0, movement: new cv.Point(0, 0) }
  }

  // Use BFMatcher for feature matching
  const bf = new cv.BFMatcher(cv.NORM_HAMMING, false)
  const matches = new cv.DMatchVectorVector()
  bf.knnMatch(descriptors1, descriptors2, matches, 2)

  // Apply Lowe's ratio test
  const goodMatches: any[] = []
  for (let i = 0; i < matches.size(); i++) {
    const m = matches.get(i).get(0)
    const n = matches.get(i).get(1)
    if (m.distance < 0.75 * n.distance) {
      goodMatches.push(m)
    }
  }

  // If there are enough good matches, calculate displacement vector
  if (goodMatches.length > 5) {
    let movementX = 0
    let movementY = 0

    for (let i = 0; i < goodMatches.length; i++) {
      const pt1 = keypoints1.get(goodMatches[i].queryIdx).pt
      const pt2 = keypoints2.get(goodMatches[i].trainIdx).pt
      movementX += pt2.x - pt1.x
      movementY += pt2.y - pt1.y
    }

    movementX /= goodMatches.length
    movementY /= goodMatches.length

    // Calculate distance and angle
    const centerX = curentMat.cols / 2
    const centerY = curentMat.rows / 2
    const endX = centerX - movementX
    const endY = centerY - movementY

    const centerPoint = new cv.Point(centerX, centerY)
    const endPoint = new cv.Point(endX, endY)

    const distance = calculateDistance(centerPoint, endPoint)
    const angle = calculateAngle(centerPoint, endPoint)

    drawLine(curentMat, centerPoint, endPoint, new cv.Scalar(0, 0, 255, 255)) // è“è‰²çº¿

    cv.imshow('canvasOutput', curentMat)

    return { distance, angle, movement: new cv.Point(movementX, movementY) }
  } else {
    return { distance: 0, angle: 0, movement: new cv.Point(0, 0) }
  }
}

export const detectMovement2 = async (currentImg: string, targetImg: string) => {
  const [curentMat, targetMat] = await Promise.all([
    base64ToMat(currentImg),
    base64ToMat(targetImg)
  ])

  // Convert to grayscale
  const grayCurrent = new cv.Mat()
  const grayPrevious = new cv.Mat()
  cv.cvtColor(curentMat, grayCurrent, cv.COLOR_BGR2GRAY)
  cv.cvtColor(targetMat, grayPrevious, cv.COLOR_BGR2GRAY)
  // Create ORB object
  const orb = new cv.ORB(5000, 1.2, 8, 15)

  // Detect ORB keypoints and descriptors
  const keypoints1 = new cv.KeyPointVector()
  const keypoints2 = new cv.KeyPointVector()
  const descriptors1 = new cv.Mat()
  const descriptors2 = new cv.Mat()
  orb.detectAndCompute(grayPrevious, new cv.Mat(), keypoints1, descriptors1)
  orb.detectAndCompute(grayCurrent, new cv.Mat(), keypoints2, descriptors2)

  // Check if descriptors are empty
  if (descriptors1.rows === 0 || descriptors2.rows === 0) {
    return { distance: 0, angle: 0, movement: new cv.Point(0, 0) }
  }

  // Use BFMatcher for feature matching
  const bf = new cv.BFMatcher(cv.NORM_HAMMING, false)
  const matches = new cv.DMatchVectorVector()
  bf.knnMatch(descriptors1, descriptors2, matches, 2)

  // Apply Lowe's ratio test
  const goodMatches: any[] = []
  for (let i = 0; i < matches.size(); i++) {
    const m = matches.get(i).get(0)
    const n = matches.get(i).get(1)
    if (m.distance < 0.75 * n.distance) {
      goodMatches.push(m)
    }
  }

  // If there are enough good matches, calculate displacement vector
  if (goodMatches.length > 5) {
    const pts1: Point[] = []
    const pts2: Point[] = []
    for (let i = 0; i < goodMatches.length; i++) {
      pts1.push(keypoints1.get(goodMatches[i].queryIdx).pt)
      pts2.push(keypoints2.get(goodMatches[i].trainIdx).pt)
    }

    const pts1Mat = cv.matFromArray(
      pts1.length,
      1,
      cv.CV_32FC2,
      ([] as any[]).concat(...pts1.map((p) => [p.x, p.y]))
    )
    const pts2Mat = cv.matFromArray(
      pts2.length,
      1,
      cv.CV_32FC2,
      ([] as any[]).concat(...pts2.map((p) => [p.x, p.y]))
    )

    const mask = new cv.Mat()
    cv.findHomography(pts1Mat, pts2Mat, cv.RANSAC, 5.0, mask)
    const matchesMask = mask.data

    // Calculate movement only for inliers after RANSAC
    let movementX = 0
    let movementY = 0
    let inlierCount = 0
    for (let i = 0; i < matchesMask.length; i++) {
      if (matchesMask[i]) {
        movementX += pts2[i].x - pts1[i].x
        movementY += pts2[i].y - pts1[i].y
        inlierCount++
      }
    }

    if (inlierCount > 0) {
      movementX /= inlierCount
      movementY /= inlierCount

      // Calculate distance and angle
      const centerX = curentMat.cols / 2
      const centerY = curentMat.rows / 2
      const endX = centerX - movementX
      const endY = centerY - movementY

      const centerPoint = new cv.Point(centerX, centerY)
      const endPoint = new cv.Point(endX, endY)

      const distance = calculateDistance(centerPoint, endPoint)
      const angle = calculateAngle(centerPoint, endPoint)

      drawLine(curentMat, centerPoint, endPoint, new cv.Scalar(0, 0, 255, 255)) // è“è‰²çº¿

      cv.imshow('canvasOutput', curentMat)

      return { distance, angle, movement: new cv.Point(movementX, movementY) }
    } else {
      return { distance: 0, angle: 0, movement: new cv.Point(0, 0) }
    }
  } else {
    return { distance: 0, angle: 0, movement: new cv.Point(0, 0) }
  }
}

/** è®¡ç®—çˆ¶å›¾ä¸­ç›®æ ‡å›¾ç‰‡çš„ä½ç½® */
export const ImageInfoInParent = async (largeBase64: string, smallBase64: string) => {
  // è¯»å–å¤§å›¾å¹¶è½¬æ¢ä¸ºOpenCVçŸ©é˜µ
  // åŠ è½½å°å›¾å¹¶è½¬æ¢ä¸ºOpenCVçŸ©é˜µ
  const [largeMat, smallMat] = await Promise.all([
    base64ToMat(largeBase64),
    base64ToMat(smallBase64)
  ])

  // è½¬ä¸ºç°åº¦å›¾åƒ
  cv.cvtColor(largeMat, largeMat, cv.COLOR_RGBA2GRAY)
  cv.cvtColor(smallMat, smallMat, cv.COLOR_RGBA2GRAY)

  // // å¯¹å›¾åƒè¿›è¡ŒäºŒå€¼åŒ–å¤„ç†
  // cv.threshold(largeMat, largeMat, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)
  // cv.threshold(smallMat, smallMat, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)

  // åˆ›å»ºçŸ©é˜µä»¥å­˜å‚¨åŒ¹é…ç»“æœ
  const result = new cv.Mat()
  const mask = new cv.Mat()

  // å¯¹å¤§å›¾å’Œå°å›¾è¿›è¡Œæ¨¡æ¿åŒ¹é…
  cv.matchTemplate(largeMat, smallMat, result, cv.TM_CCOEFF_NORMED, mask)

  // è·å–åŒ¹é…ç»“æœçš„æœ€ä¼˜ä½ç½®
  const minMaxLocResult = cv.minMaxLoc(result, mask)
  const maxPoint = minMaxLocResult.maxLoc
  // è®¡ç®—å°å›¾åœ¨å¤§å›¾ä¸Šçš„ä¸­å¿ƒç‚¹
  const targetPoint = calculateCenter(maxPoint, smallMat)

  // è·å–åŒ¹é…åº¦ï¼ˆåˆ†æ•°ï¼‰
  const score = cv.minMaxLoc(result, mask).maxVal

  // Clean up
  largeMat.delete()
  smallMat.delete()
  result.delete()

  return {
    center: targetPoint,
    score: score === 1 ? 0 : score
  }
}

/** ç»˜åˆ¶è·¯å¾„ç‚¹ */
export const drawRoute = async () => {
  // è·å–ç”»å¸ƒå…ƒç´ å’Œä¸Šä¸‹æ–‡
  const canvas = document.getElementById('canvasOutput') as HTMLCanvasElement
  if (!canvas) return

  // æ¸…ç©ºcanvas
  const ctx = canvas.getContext('2d')
  ctx!.fillStyle = 'white'
  ctx!.fillRect(0, 0, canvas.width, canvas.height)

  const mat = cv.imread(canvas)

  // å®šä¹‰åæ ‡ç‚¹æ•°ç»„
  const points = [
    { x: 50, y: 50 },
    { x: 100, y: 100 },
    { x: 150, y: 50 },
    { x: 200, y: 100 }
  ]

  // å°†åæ ‡ç‚¹è½¬æ¢ä¸º OpenCV çš„ Point æ•°ç»„å¹¶ç»˜åˆ¶çº¿æ¡
  for (let i = 0; i < points.length - 1; i++) {
    const pt1 = new cv.Point(points[i].x, points[i].y)
    const pt2 = new cv.Point(points[i + 1].x, points[i + 1].y)
    drawLine(mat, pt1, pt2, new cv.Scalar(255, 0, 0, 255))
  }

  // å°†ç»˜åˆ¶çš„å†…å®¹æ˜¾ç¤ºåœ¨ç”»å¸ƒä¸Š
  cv.imshow('canvasOutput', mat)
  mat.delete() // é‡Šæ”¾å†…å­˜
}

/** ä½¿ç”¨ Tesseract.js è¿›è¡Œ OCR è¯†åˆ« */
export const recognize = async (base64: string) => {
  const mat = await base64ToMat(base64)

  const dst = new cv.Mat()

  // å°†å›¾åƒè½¬æ¢ä¸ºç°åº¦å›¾
  cv.cvtColor(mat, dst, cv.COLOR_RGBA2GRAY)

  // å¯¹å›¾åƒè¿›è¡ŒäºŒå€¼åŒ–å¤„ç†
  // cv.threshold(dst, dst, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)

  // å°†ç»“æœæ˜¾ç¤ºåœ¨canvasä¸­
  cv.imshow('canvasOutput', dst)

  // å¦‚æœéœ€è¦å°†ç°åº¦å›¾è½¬æ¢å›base64
  const grayBase64 = matToBase64(dst)

  // è®°å¾—é‡Šæ”¾èµ„æº
  mat.delete()
  dst.delete()

  const { data } = await Tesseract.recognize(
    grayBase64,
    'eng', // å¯ä»¥æ”¹ä¸º 'digits' æˆ–å…¶ä»–è¯­è¨€æ¨¡å‹
    {
      // logger: (m) => console.log(m)
      // langPath: './eng.traineddata' // æ¨¡å‹çš„å­˜æ”¾è·¯å¾„
    }
  )
  return data.text.trim()
}
